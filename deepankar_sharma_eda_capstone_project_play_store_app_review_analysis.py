# -*- coding: utf-8 -*-
"""Deepankar Sharma-EDA Capstone Project -Play Store App Review Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CTm5TwY4Q2pSQNJFekIPSNePRNNgKvws

# **Welcome!** 
The respective project is based on the Data Set provided by AlmaBetter on Google Play Store.
The idea of the project is drive out meaningful insights from the Data for business to maximise their growth and reduce their expenses

## **Project Description**
## The Play Store apps data has enormous potential to drive app-making businesses to success. Actionable insights can be drawn for developers to work on and capture the Android market.Each app (row) has values for catergory, rating, size, and more. Another dataset contains customer reviews of the android apps.
### **Problem Statement**
Explore and analyze the data to discover key factors responsible for app engagement and success.

The Data set will be analyzed using Python language as the language provides great tools for analysis through its plethora of libraries.

For various purposes, we will be using different libraries -

1. Mathematical and statistical purposes, we will use - 
    
*   Pandas library 
*   NumPy library 

2. Visualisations and Plotting, will be done through - 

*   Matplotlib.Py library 
*   Seaborn library 

3. Import Data Library

*   OS
*   Glob

# **Data Cleaning**
A very important aspect of Data Analysis is Data Cleaning, since Data comes from various sources and alot of times, this data that we receive isn't cleaning.

It contains missing values called as *null values* or NaN values, the best solution to such problem is to fill in these values from primary source but it is seldom possible, so we remove the null value Data and analyze.

There also miss represented values that are completely out of context.

For Ex - Presence of Date in genre column, in such cases also we drop values

In some cases, where data can be replaced by a more common value, we replace it. 

For Ex - if Budget of certain movies are misrepresented, we replace those values with average value of movie budget in that Data Set

#**Data Analysis**
Next step to Data cleaning is Data Analysis

First, the required information is fetched for Data analysis, to understand better what data is saying. 

One has to be sure that during Data Analysis personal basis or personal experiences should not be taken into consideration as it can queston the credibility of analysis.

However, Understanding of one's domain of knowledge is equally important to understand what data is trying to say.

# **Data Visualisation**
*One picture is worth thousand words 
               -  Sir Albert Einstein*
Visualisation is important point of contact between client and the analyst, these visualisations help us understand the Data better,simpler and faster.
"""

# Importing Data set
from google.colab import drive 
drive.mount('/content/drive')
import pandas as pd
import numpy as np 
import os 
import glob
import matplotlib.pyplot as plt
import seaborn as sns
path_file = '/content/drive/MyDrive/AlmaBetter/data/Play Store App Review Analysis'
csv_file = glob.glob(os.path.join(path_file,"*.csv"))

"""Since, the Data is a collection of multiple Data Set it is important for us, to see our Data. Thus, Here we have used glob module to Import all the dataset that were present inside the folder 'Data'.

Below, I have displayed all the Data sets that are present in inside the folder.
"""

i = 1
lst = []
for f in csv_file:
  df= pd.read_csv(f)
  print(f"DATA SET - {i}")
  i += 1
  print(f.split('/')[-1])
  lst.append(f.split('/')[-1])
  display(df)

lst

"""The following are the columns of each Data Set - """

Reviews_Set = pd.read_csv(path_file + '/' + lst[0])
PlayStore_Set = pd.read_csv(path_file + '/' + lst[1])

print(PlayStore_Set.columns)
print(Reviews_Set.columns)

"""Now, lets find out highest rated applications on PlayStore. """

no_na_rating = PlayStore_Set.loc[~PlayStore_Set['Rating'].isna()]
no_na_rating.loc[no_na_rating['Rating'].idxmax()]
no_na_rating.loc[no_na_rating['Rating'] == 19] = no_na_rating['Rating'].median()
no_na_rating['Rating'].unique()

"""Since, you notice that there is a value equal to 19,this value is an *Outlier* such error can occur while documenting the data 

The best approach here is replace this value with the median value in the Data set

We are interested to know, that which application genre has highest average rating, since that shows
"""

Highest_Avg_Rating=no_na_rating.groupby(['Category'])['Rating'].mean().reset_index().sort_values(by='Rating',ascending=False)
Highest_Avg_Rating=Highest_Avg_Rating[~(Highest_Avg_Rating['Category'] == 4.3)]
Highest_Avg_Rating

from matplotlib import rcParams
rcParams['figure.figsize'] = 20,10
Category_ = Highest_Avg_Rating['Category'].to_list()
print(Category_)
Category_list = [i[:3] for i in Category_]
print(Category_list)
Rating_list = Highest_Avg_Rating['Rating'].to_list()
Data_1=dict(zip(Category_list,Rating_list))

grp_1 = sns.lineplot(data=Data_1).set(title='Mean Rating in different Categories')
sns.set(font_scale=1.0)

(no_na_rating.groupby(['Category'])['Rating'].mean()).reset_index().sort_values(by='Rating',ascending=False).head(3)

no_na_rating['Rating'].unique()
Rating_data = no_na_rating[['App','Rating']].reset_index(drop=True).drop_duplicates(subset='App')
Rating_Apps=Rating_data.groupby(['Rating']).count().reset_index().rename(columns = {'App':'No of Apps'})
Rating_Apps

sns.stripplot(data=Rating_Apps,x='Rating',y='No of Apps',size=10).set(title="Rating Density of Apps")
sns.set(font_scale=1.5)

"""From observing Data above one can understand that most of applications are rated 4-4.6.
Very less applications are either highly rated or lowly rated.

In order to understand the market better, we need to which Category of Apps are dominant in the market.
"""

PlayStore_Set=PlayStore_Set.loc[~(PlayStore_Set['Category'] == '1.9')]
PlayStore_Set.groupby('Category')['App'].count().reset_index()
Category_Count_Frame = PlayStore_Set.groupby('Category')['App'].count().reset_index()
print(Category_Count_Frame)
total_no_of_apps = Category_Count_Frame.sum()
total_no_of_apps

# Now, we will create a function of percentage of the Category
def percentage_app(apps):
   x = (apps/10840)*100
   return x

Category_Count_Frame['Percentage'] = Category_Count_Frame.apply(lambda x: percentage_app(x['App']),axis=1)
Category_Count_Frame.sort_values(by='Percentage',ascending=False)
sns.barplot(data=Category_Count_Frame.sort_values(by='Percentage',ascending=False).head(5),x='Category',y='Percentage').set(title='Highest Percentage Applications on Playstore')

"""Here, we can aggregate these values and find out the category with **maximum highest ratings**.

Here, one more thing to notice is that Rating is dependent quantity to reviews, we need understand the correlation between the **Rating** and **Review**, which gives us the true picture of the Data
"""

type(no_na_rating['Reviews'][1])

def str_to_int(str):
  return int(str)

no_na_rating['Reviews'] = no_na_rating['Reviews'].apply(str_to_int)
print(type(no_na_rating['Reviews'][1]))

"""Here, The values of **Reviews** is in String format, we will convert the Data from String format to Int format for the ease of analysis"""

## Removing the null or misrepresented values
no_na_rating[no_na_rating['Reviews'].isnull()]

"""So, our Data does not contain any null values for Reviews. Thus,we are good to go !!!!

Lets compare values Ratings V/s Reviews
"""

no_na_rating[['App','Reviews','Rating']].sort_values(by=['Reviews','Rating'],ascending=False).drop_duplicates(subset='App').head(10).reset_index(drop=True)

"""On comparing values, our review vs rating we come across the top 20 actual applications. 
So, now we create a product of rating and review to understand with higher accuracy that what apps are actually being rated high with higher number of reviews.
"""

PlayStore_Set['Reviews']

def Review_Rating(Rating,Reviews):
  product = Rating*Reviews
  return product

no_na_rating['Review_Rating'] = no_na_rating.apply(lambda x: Review_Rating(x['Reviews'],x['Rating']),axis=1)

"""**Top 10 Applications on Playstore**"""

Top_rated_App=no_na_rating.sort_values(by=['Review_Rating'],ascending=False).drop_duplicates(subset='App').head(10).reset_index(drop=True)
Top_rated_App
Top_rated_App[['App','Review_Rating']]

"""**Below given is the category-wise disturbution of Top 10 applications in the Playstore**"""

(Top_rated_App.drop_duplicates(subset='App').groupby(['Category'])['App']).count().reset_index().sort_values(by='App',ascending=False).head(10)

# lets create acronyms
def create_acronyms(word):
  return word[:4]

Top_rated_App['Apps_Acronym'] = Top_rated_App.apply(lambda x: create_acronyms(x['App']),axis=1)
Top_rated_App

sns.relplot(data=Top_rated_App,y='Reviews',x='Apps_Acronym',hue='Category',size='Rating',height=10)

"""Now, we are interested in knowing the top application for each Category """

no_na_rating = no_na_rating[~(no_na_rating['Category'] == 4.3)]

max_review_rating=no_na_rating.groupby(['Category'])['Review_Rating'].max().reset_index()
max_review_rating

df = pd.DataFrame()

for index,i in max_review_rating.iterrows():
   df =df.append(no_na_rating.loc[no_na_rating['Review_Rating'] == max_review_rating['Review_Rating'][index]])

df = df.drop_duplicates(subset='App').reset_index(drop=True)
#df = df.drop(columns=['index'])

df

sns.stripplot(data=df,y='Category',x='Rating',size=10)

"""Another criteria to understand the success of an application is the number of user of that application.

However, Instead of users we are provided with the number of installs

lets find out the highest number of applications that are being installed. 
"""

def remove_plus(word):
  word = word.replace('+','').replace(',','')
  return word

int(remove_plus('10,+0'))

PlayStore_Set['Installs'] = PlayStore_Set['Installs'].apply(remove_plus)
PlayStore_Set['Installs'] = PlayStore_Set['Installs'].apply(str_to_int)
Max_Installs=PlayStore_Set.sort_values(by='Installs',ascending=False).drop_duplicates(subset='App')

Max_Installs.head(200)
Max_Installs.head(10)



sns.scatterplot(data=Max_Installs,y='Installs',x='Rating',hue='Type',size='Installs')

"""Now, lets try to understand the performance of paid applications"""

def remove_Dollar(word):
  word = word.replace('$','')
  return word
def str_to_ft(word):
  return float(word)

PlayStore_Set['Price'] = PlayStore_Set['Price'].apply(remove_Dollar)
PlayStore_Set['Price'] = PlayStore_Set['Price'].apply(str_to_ft)

Paid_Apps=PlayStore_Set.loc[PlayStore_Set['Type'] == 'Paid'].drop_duplicates(subset='App').reset_index(drop=True)
Paid_Apps.sort_values(by='Price',ascending=False)

sns.boxplot(data=Paid_Apps,y='Price').set_ylim(0,20)

PlayStore_Set['Reviews'] = PlayStore_Set['Reviews'].apply(str_to_int)
PlayStore_Set['Review_Rating'] = PlayStore_Set.apply(lambda x: Review_Rating(x['Reviews'],x['Rating']),axis=1)
Top_10_Paid_Apps=PlayStore_Set.loc[PlayStore_Set['Type'] == 'Paid'].sort_values(by=['Review_Rating'],ascending=False).drop_duplicates(subset='App').reset_index(drop=True).head(10)

Top_10_Paid_Apps

sns.catplot(data=Top_10_Paid_Apps,x='Rating',y='Price',hue='Category')

"""As we can see that, there are very few paid applications on Play store, lets see how many applications are """

print(PlayStore_Set.groupby('Type')['App'].count())

"""## Lets find out the percentage of paid and free applications available on Play store"""

FreeApps_percentage=(PlayStore_Set.groupby('Type')['App'].count()[0]/PlayStore_Set.groupby('Type')['App'].count().sum())*100
PaidApps_percentage=(PlayStore_Set.groupby('Type')['App'].count()[1]/PlayStore_Set.groupby('Type')['App'].count().sum())*100

print(FreeApps_percentage)
print(PaidApps_percentage)

"""We another dataset called as Reviews_Set, we will now extract data from that set"""

Reviews_Set

"""### We will look into types of reviews and understand the response ratio of sentiment response"""

Reviews_Set=Reviews_Set.loc[~Reviews_Set['Sentiment'].isnull()]
Review_Frame=Reviews_Set.groupby('Sentiment')['App'].count().reset_index()
Review_Frame

sns.lineplot(data=Review_Frame,x='Sentiment',y='App')

"""### Data provides the translated review which is a written response, here we have extracted most frequently used words for applications """

PlayStore_1=PlayStore_Set.drop_duplicates(subset='App')
main_frame = pd.merge(PlayStore_1,Reviews_Set,on='App',how='inner')
main_frame

def list_words(index):
  sentence = main_frame.loc[index,'Translated_Review']
  lst=sentence.replace(',',"").replace('.','').split()
  l = []
  for i in lst:
    if len(i) > 3:     
      l.append(i)
  return l

list_words(0)

df_name = pd.DataFrame()

for index,i in main_frame.iterrows():
  try:
      df_name = df_name.append({'Application':main_frame.loc[index,'App'],'Words':list_words(index)},ignore_index=True)
  except:
    continue

df_name

df_Words=df_name.groupby('Application')
df_Words.first()

df_4 = pd.DataFrame()

for i in df_name.drop_duplicates(subset='Application')['Application']:
  l = []
  count = 0
  for word in df_Words.get_group(i)['Words']:
    for w in word:
      l.append(w)
  df_4 = df_4.append({'Name':i,'Highest Frequency': max(l,key=l.count)},ignore_index=True)

df_4.sort_values(by='Highest Frequency')

data_1 = df_4.groupby('Highest Frequency').count().sort_values(by="Name",ascending=False).reset_index().head(10)
data_1

sns.lineplot(data=data_1,x='Highest Frequency',y='Name').set_ylabel('Counts')

